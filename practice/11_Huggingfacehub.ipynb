{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Potato is a starchy vegetable that is grown underground in rows in a shallow, well-drained soil. It is a tuber, which means it is an underground, fleshy part of the plant that stores nutrients. Potatoes are a popular food source and are used in many different dishes, including salads, soups, stews, and baked dishes. They are also used as a source of starch for making paper and other products. Potatoes are high in carbohydrates and are a good source of fiber, vitamin C, and potassium.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"[INST]What is the meaning of {word}[/INST]\")\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "\trepo_id = \"mistralai/Mistral-7B-v0.1\",\n",
    "\tmodel_kwargs={\"max_new_tokens\":250},\n",
    ")\n",
    "\n",
    "llm.client.api_url = 'https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\"word\": \"potato\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" juice? And what is it for? Well, the tomato juice is a great little flavor enhancer, and is essential to some great tasting and spicy sauces and sauces.\\n\\n\\nWe use one of a small group of other great tomato juices, which are called pilsner sous-vide.\\n\\nWe use different flavors of tomatoes, some are less sweet and some are sweeter. So, we don't make up the total energy and volume of juice that you might think. We just know what those flavors are. And you can't just mix these flavors without looking at all that information.\\n\\n\\nPilsner sous-vide is a very large, concentrated, pungent flavor, a really good one.\\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is {word}\")\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "\tmodel_id = \"gpt2\",\n",
    "\ttask=\"text-generation\",\n",
    "\tpipeline_kwargs={\"max_new_tokens\":150},\n",
    ")\n",
    "\n",
    "#llm.client.api_url = 'https://api-inference.huggingface.co/models/openai-community/gpt2'\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\"word\": \"tomato\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT4 all 다운받아야 해서 별도 실행은 하지 않음, \n",
    "# .gitignore에 falcon.bin 를 추가 필요함. 또한 그렇기 위해, 파일에 falcon.bin를 생성하기도 해야함\n",
    "from langchain.llms.gpt4all import GPT4All\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"You are a helpful assistant that defines words. Define this word: {word}.\"\n",
    ")\n",
    "\"\"\"\n",
    "llm = GPT4All(\n",
    "    model=\"./falcon.bin\",\n",
    ")\n",
    "\"\"\"\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\"word\": \"tomato\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
