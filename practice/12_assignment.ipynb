{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True, return_message=True,)\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./rag_data/chapter_3.txt\")\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. {context}\n",
    "\n",
    "Question: {question}\n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "\tllm=llm,\n",
    "\tchain_type=\"stuff\", \n",
    "\tretriever=vectorstore.as_retriever(),\n",
    "\tmemory=memory,\n",
    "\tchain_type_kwargs={\"prompt\":prompt},\n",
    ")\n",
    "\n",
    "def invoke_chain(question):\n",
    "\tresult = chain.invoke({\"query\":question})\n",
    "\tprint(f\"Question: {question}\")\n",
    "\tprint(f\"Answer: {result['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Aaronson 은 유죄인가요?\n",
      "Answer: I don't know.\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Aaronson 은 유죄인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 그가 테이블에 어떤 메시지를 썼나요?\n",
      "Answer: 그가 쓴 메시지는 \"FREEDOM IS SLAVERY\"이었고, 그 아래에 \"TWO AND TWO MAKE FIVE\"와 \"GOD IS POWER\"라고 썼습니다.\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"그가 테이블에 어떤 메시지를 썼나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Julia 는 누구인가요?\n",
      "Answer: Julia is a character in the novel who is involved in a romantic relationship with Winston, the main character.\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Julia 는 누구인가요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG(Retrieval-Augmented Generation) 시스템에서의 Context\n",
    "\n",
    "## 질문\n",
    "\"주어진 코드에서 `context` 변수가 불필요한 것 아닌가요? 명시적으로 정의되지 않았는데 왜 프롬프트 템플릿에 그것의 자리 표시자가 있나요?\"\n",
    "\n",
    "## 답변\n",
    "`context` 변수는 코드에서 명시적으로 정의되지 않았지만, RAG 시스템의 중요한 구성 요소입니다. 자세한 설명은 다음과 같습니다:\n",
    "\n",
    "### 1. 프롬프트 템플릿에서 `{context}`의 역할\n",
    "\n",
    "프롬프트 템플릿에는 `{context}`를 위한 자리 표시자가 포함되어 있습니다:\n",
    "\n",
    "```python\n",
    "prompt_template = \"\"\"\n",
    "다음의 컨텍스트를 사용하여 마지막에 있는 질문에 답하세요. \n",
    "답을 모르는 경우, 모른다고 말하고 답을 만들어내려 하지 마세요. {context}\n",
    "\n",
    "질문: {question}\n",
    "답변: \n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "이 자리 표시자가 필요한 이유는:\n",
    "\n",
    "- 시스템이 검색한 관련 문서 조각들로 채워질 것입니다.\n",
    "- 언어 모델(LLM)에게 질문에 정확히 답하기 위해 필요한 배경 정보를 제공합니다.\n",
    "\n",
    "### 2. `context`가 처리되는 방식\n",
    "\n",
    "명시적으로 정의되지 않았지만, `context`는 RAG 시스템 내부에서 다음과 같이 관리됩니다:\n",
    "\n",
    "1. `vectorstore.as_retriever()`가 사용자의 질문을 기반으로 관련 문서 조각들을 검색합니다.\n",
    "2. 이 조각들이 `context`로 사용됩니다.\n",
    "3. RetrievalQA 체인이 자동으로 이 `context`를 프롬프트 템플릿에 주입합니다.\n",
    "\n",
    "### 3. `{context}` 자리 표시자의 중요성\n",
    "\n",
    "`{context}` 자리 표시자를 제거하면 안 되는 이유는:\n",
    "\n",
    "- 각 쿼리에 대해 관련 정보를 주입하는 곳이기 때문입니다.\n",
    "- 제거하면 RAG 시스템의 핵심 기능이 비활성화됩니다.\n",
    "- 이것이 없으면 LLM은 사전 학습된 지식에만 의존하게 되어, 덜 정확하거나 관련성이 낮은 답변을 제공할 수 있습니다.\n",
    "\n",
    "### 4. 동적 컨텍스트 주입\n",
    "\n",
    "- `{context}` 자리 표시자를 채우는 내용은 각 쿼리마다 변경됩니다.\n",
    "- 이 동적 주입을 통해 시스템은 각 특정 질문에 가장 관련된 정보를 제공할 수 있습니다.\n",
    "\n",
    "### 5. 프롬프트 엔지니어링의 일부\n",
    "\n",
    "- `{context}`의 배치와 사용은 프롬프트 엔지니어링의 중요한 측면입니다.\n",
    "- 이는 LLM에게 제공된 정보를 바탕으로 답변하라고 효과적으로 지시합니다.\n",
    "\n",
    "## 결론\n",
    "\n",
    "프롬프트 템플릿의 `{context}` 자리 표시자는 RAG 시스템의 핵심 구성 요소입니다. 이를 통해 관련 정보를 동적으로 주입할 수 있어, LLM이 검색된 문서 조각들을 바탕으로 정확하고 컨텍스트에 특화된 답변을 제공할 수 있게 됩니다. 사용자의 코드에서 명시적으로 정의되지 않았지만, RetrievalQA 체인 내부에서 처리되어 시스템 기능의 핵심 부분을 형성합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
